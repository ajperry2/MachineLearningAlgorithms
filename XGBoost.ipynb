{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T07:40:04.621408Z",
     "start_time": "2019-06-01T07:40:04.608496Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:22:35.444587Z",
     "start_time": "2019-06-01T08:22:35.440722Z"
    }
   },
   "outputs": [],
   "source": [
    "toy_data = np.array([\n",
    "    [1,2,4],\n",
    "    [1,1,1],\n",
    "    [0,0,5],\n",
    "    [4,2,2]\n",
    "])\n",
    "toy_y= np.array([1.5,2.3,1.2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:47:25.492810Z",
     "start_time": "2019-06-01T08:47:25.477077Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGBoostRegressor():\n",
    "    def __init__(self,X:np.ndarray,y:np.ndarray,num_trees=1,num_splits=10,max_depth = 1, learning_rate = 1):\n",
    "        self.constants = np.ones_like(y) * y.mean()\n",
    "        self.tree = None\n",
    "        for i in range(num_trees):\n",
    "            curr_targ = y - self.constants\n",
    "            self.tree = self.__DecisionTreeRegressor__(X,curr_targ,max_depth,num_splits)\n",
    "            self.constants+=   self.tree.predict(X)\n",
    "    def predict(self, X):\n",
    "        return self.tree.predict(X)\n",
    "    class __DecisionTreeRegressor__():\n",
    "        def __init__(self,X:np.ndarray,y:np.ndarray,max_depth,num_splits):\n",
    "            '''\n",
    "            Decision Tree Classifier:\n",
    "            Parameters:\n",
    "                X: An array of numerical factors\n",
    "                y: The responding variable, must be continuous\n",
    "                max_depth: The maximum number of nodes from root to leaves in each estimator\n",
    "                num_splits: The number of splits to be tested for each factor at each node\n",
    "            '''\n",
    "            self.tree = self.Node_(X,y,max_depth,num_splits,self,0)\n",
    "\n",
    "        def predict(self,X):\n",
    "            '''\n",
    "            Predict:\n",
    "            Predicts using the established tree\n",
    "\n",
    "            Parameters:\n",
    "                X: An array of numerical factors\n",
    "\n",
    "            Returns:\n",
    "                An array of predictions.\n",
    "            '''            \n",
    "            total_predictions=[]\n",
    "            for x in X:\n",
    "                node = self.tree\n",
    "                while node.prediction_value is None:\n",
    "                    #decend tree\n",
    "                    if x[node.split_characteristic] <= node.split: node = node.left\n",
    "                    else: node = node.right\n",
    "                total_predictions.append(node.prediction_value)\n",
    "            return np.array(total_predictions)\n",
    "        class Node_():\n",
    "            def __init__(self, X,y, max_depth, num_splits, tree=None,current_depth=0):\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "                self.tree = tree\n",
    "                #calculate entropy\n",
    "                classes = np.unique(y)\n",
    "                if len(classes) == 1:\n",
    "                    self.prediction_value = classes[0]\n",
    "                    return #early stopping if we have prematurely gotten a 'Pure Node'\n",
    "                # get the proportions of each class in y\n",
    "                p_classes = []\n",
    "                for class_ in classes:\n",
    "                    p_class = np.sum(y==class_)/len(y)\n",
    "                    p_classes.append(p_class)\n",
    "\n",
    "                variances = [] # used to find best split\n",
    "                total_splits = []\n",
    "                for column_index in range(X.shape[1]):\n",
    "                    curr_column = X[:,column_index]\n",
    "\n",
    "                    #pick 10 random potential split points\n",
    "                    random_splits = np.random.random_sample(num_splits,)*(curr_column.max()-curr_column.min())\\\n",
    "                                    + curr_column.min()\n",
    "                    total_splits = np.concatenate([total_splits, random_splits],axis=0)\n",
    "    \n",
    "                    # decide on best split using information gain\n",
    "                    for split in random_splits:\n",
    "                        #find combined mse for each split\n",
    "\n",
    "                        y_lower = y[curr_column<=split]\n",
    "                        y_higher = y[curr_column>split]\n",
    "                        y_lower_mean = y_lower.mean()\n",
    "                        y_higher_mean = y_higher.mean()\n",
    "         \n",
    "        \n",
    "                        variances.append(((y_lower-y_lower_mean)**2).sum()+((y_higher-y_higher_mean)**2).sum())\n",
    "\n",
    "                # split using best splitpoint\n",
    "                arg_min = np.argmin(np.array(variances))\n",
    "\n",
    "                self.split_characteristic = arg_min // len(random_splits)\n",
    "\n",
    "                final_split = total_splits[arg_min]\n",
    "\n",
    "                self.split = final_split\n",
    "\n",
    "                final_X_lower = X[X[:,self.split_characteristic]<=self.split, :]\n",
    "                final_X_higher = X[X[:,self.split_characteristic]>self.split, :]\n",
    "                final_y_lower = y[X[:,self.split_characteristic]<=self.split]\n",
    "                final_y_higher = y[X[:,self.split_characteristic]>self.split]\n",
    "                #assign children\n",
    "                if current_depth<max_depth:\n",
    "                    self.left = self.tree.Node_(final_X_lower,\\\n",
    "                                                final_y_lower,\\\n",
    "                                                max_depth,\\\n",
    "                                                num_splits,\\\n",
    "                                                self.tree,\\\n",
    "                                                current_depth+1)\n",
    "                    self.right = self.tree.Node_(final_X_higher,\\\n",
    "                                                 final_y_higher,\\\n",
    "                                                 max_depth,\\\n",
    "                                                 num_splits,\\\n",
    "                                                 self.tree,\\\n",
    "                                                 current_depth+1)\n",
    "                    self.prediction_value = None\n",
    "                else:\n",
    "                    #value to predict with\n",
    "                    self.prediction_value = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:47:26.354746Z",
     "start_time": "2019-06-01T08:47:26.319323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00003387 1.99989839 1.00003387 5.00003387]\n"
     ]
    }
   ],
   "source": [
    "regress = XGBoostRegressor(toy_data,toy_y,num_trees=10)\n",
    "\n",
    "print((toy_y-regress.predict(toy_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:47:27.372683Z",
     "start_time": "2019-06-01T08:47:27.291388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 1. 5.]\n"
     ]
    }
   ],
   "source": [
    "regress = XGBoostRegressor(toy_data,toy_y,num_trees=50)\n",
    "print((toy_y-regress.predict(toy_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:48:00.266025Z",
     "start_time": "2019-06-01T08:48:00.244753Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier():\n",
    "    def __init__(self,X:np.ndarray,y:np.ndarray,num_trees=1,num_splits=10,max_depth = 1, learning_rate = 1):\n",
    "        self.constants = np.ones_like(y) * np.median(y)\n",
    "        self.tree=None\n",
    "        for i in range(num_trees):\n",
    "            curr_targ = (y - self.constants)>0\n",
    "            self.tree = self.__DecisionTreeClassifier__(X,curr_targ,max_depth,num_splits)\n",
    "            print( self.tree.predict(X))\n",
    "            self.constants+=   self.tree.predict(X)\n",
    "    def predict(self, X):\n",
    "        return self.tree.predict(X)\n",
    "    class __DecisionTreeClassifier__():\n",
    "        def __init__(self,X:np.ndarray,y:np.ndarray,max_depth,num_splits):\n",
    "            '''\n",
    "            Decision Tree Classifier:\n",
    "            Parameters:\n",
    "                X: An array of numerical factors\n",
    "                y: The responding variable, must be categorical\n",
    "                max_depth: The maximum number of nodes from root to leaves in each estimator\n",
    "                num_splits: The number of splits to be tested for each factor at each node\n",
    "            '''\n",
    "            self.tree = self.Node_(X,y,self,num_splits,max_depth)\n",
    "        def predict(self,X):\n",
    "            '''\n",
    "            Predict:\n",
    "            Predicts using the established tree\n",
    "\n",
    "            Parameters:\n",
    "                X: An array of numerical factors\n",
    "\n",
    "            Returns:\n",
    "                An array of predictions.\n",
    "            '''\n",
    "            total_predictions=[]\n",
    "            for x in X:\n",
    "                node = self.tree\n",
    "                while node.prediction_value is None:\n",
    "                    #decend tree\n",
    "                    if x[node.split_characteristic] <= node.split: node = node.left\n",
    "                    else: node = node.right\n",
    "                total_predictions.append(node.prediction_value)\n",
    "            return total_predictions\n",
    "        class Node_():\n",
    "            def __init__(self, X,y,tree, num_splits, max_depth,current_depth=0):\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "\n",
    "                self.tree = tree\n",
    "                #calculate entropy\n",
    "                classes = np.unique(y)\n",
    "                if len(classes) == 1:\n",
    "                    self.prediction_value = classes[0]\n",
    "                    return #early stop\n",
    "                p_classes = []\n",
    "                for class_ in classes:\n",
    "                    p_class = np.sum(y==class_)/len(y)\n",
    "                    p_classes.append(p_class)\n",
    "\n",
    "                self.entropy = -np.sum(np.array([p_class*np.log2(p_class) for p_class in p_classes]))\n",
    "\n",
    "\n",
    "                info_gains = [] # used to find best split\n",
    "                total_splits = []\n",
    "\n",
    "                for column_index in range(X.shape[1]):\n",
    "                    curr_column = X[:,column_index]\n",
    "\n",
    "                    #pick 10 random potential split points\n",
    "\n",
    "                    random_splits = np.random.random_sample(num_splits,)*(curr_column.max()-curr_column.min())\\\n",
    "                                    + curr_column.min()\n",
    "                    total_splits = np.concatenate([total_splits, random_splits],axis=0)\n",
    "\n",
    "                    # decide on best split using information gain\n",
    "                    for split in random_splits:\n",
    "\n",
    "                        y_lower = y[curr_column<=split]\n",
    "                        y_higher = y[curr_column>split]\n",
    "                        lower_p_classes = []\n",
    "                        higher_p_classes = []\n",
    "                        #find entropy of each split\n",
    "                        for class_ in classes:\n",
    "                            lower_p_class = np.sum(y_lower==class_)/len(y_lower)\n",
    "                            lower_p_classes.append(lower_p_class)    \n",
    "                            higher_p_class = np.sum(y_higher==class_)/len(y_higher)\n",
    "                            higher_p_classes.append(higher_p_class)    \n",
    "                        lower_entropy = -np.sum(np.array([p_class*np.log2(p_class) for p_class in lower_p_classes]))\n",
    "                        higher_entropy = -np.sum(np.array([p_class*np.log2(p_class) for p_class in higher_p_classes]))\n",
    "\n",
    "                        info_gains.append(self.entropy -  higher_entropy - lower_entropy)\n",
    "                # split using best splitpoint\n",
    "                arg_max = np.argmax(np.array(info_gains))\n",
    "                self.split_characteristic = arg_max // len(random_splits)\n",
    "                final_split = total_splits[arg_max]\n",
    "                self.split = final_split\n",
    "                # also split X and y\n",
    "                final_X_lower = X[X[:,self.split_characteristic]<=self.split, :]\n",
    "                final_X_higher = X[X[:,self.split_characteristic]>self.split, :]\n",
    "                final_y_lower = y[X[:,self.split_characteristic]<=self.split]\n",
    "                final_y_higher = y[X[:,self.split_characteristic]>self.split]\n",
    "                #assign children\n",
    "                if current_depth<max_depth:\n",
    "                    self.left = self.tree.Node_(X=final_X_lower,\\\n",
    "                                                y=final_y_lower,\\\n",
    "                                                tree=self.tree,\\\n",
    "                                                num_splits=num_splits,\\\n",
    "                                                max_depth=max_depth,\\\n",
    "                                                current_depth=current_depth+1)\n",
    "                    self.right = self.tree.Node_(X=final_X_higher,\\\n",
    "                                                y=final_y_higher,\\\n",
    "                                                tree=self.tree,\\\n",
    "                                                num_splits=num_splits,\\\n",
    "                                                max_depth=max_depth,\\\n",
    "                                                current_depth=current_depth+1)\n",
    "                    self.prediction_value = None\n",
    "                #asign property to be predicted\n",
    "                else:\n",
    "                    self.prediction_value = classes[np.argmax(np.array(p_classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:48:01.473503Z",
     "start_time": "2019-06-01T08:48:01.466729Z"
    }
   },
   "outputs": [],
   "source": [
    "class_data = np.array([\n",
    "    [1,2,4],\n",
    "    [1,1,1],\n",
    "    [0,0,5],\n",
    "    [4,2,2],\n",
    "        [1,2,4],\n",
    "    [1,3,1],\n",
    "    [0,1,5],\n",
    "    [4,4,2],\n",
    "        [1,2,4],\n",
    "    [2,1,1],\n",
    "    [0,2,5],\n",
    "    [4,2,3]\n",
    "])\n",
    "class_y= np.array([1,2,1,5,1,2,1,5,1,2,1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:48:01.853279Z",
     "start_time": "2019-06-01T08:48:01.790901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, True, False, False, False, True, False, False, False, True]\n",
      "[False, False, False, True, False, False, False, True, False, False, False, True]\n",
      "[False, False, False, True, False, False, False, True, False, False, False, True]\n",
      "[False, False, False, True, False, False, False, True, False, True, False, True]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:87: RuntimeWarning: divide by zero encountered in log2\n",
      "/Users/alan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/alan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:86: RuntimeWarning: divide by zero encountered in log2\n",
      "/Users/alan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "regress = XGBoostClassifier(class_data,class_y,num_trees=10)\n",
    "\n",
    "print((regress.predict(toy_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
