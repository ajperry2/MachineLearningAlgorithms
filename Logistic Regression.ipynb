{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "I chose to use gradient descent instead of using the closed form (hat matrix), because I wanted practice in implementing it.\n",
    "\n",
    "I think of logistic regression as a linear regression with a hard sigmoid function applied to the output. While the theory difference is mainly concerned with the distribution of the error terms, the implementation is not much different from OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T09:35:43.864348Z",
     "start_time": "2019-05-24T09:35:43.861116Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:27.641509Z",
     "start_time": "2019-05-24T17:47:27.627828Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegressor():\n",
    "    '''logistic regression\n",
    "    \n",
    "        Construction Parameters:\n",
    "            X: Your training input\n",
    "            y: Your training labels\n",
    "        Functions:\n",
    "            predict:\n",
    "                parameters:\n",
    "                    X: A matrix of data points to predict with current parameters\n",
    "                returns:\n",
    "                    Most likely class between 0 and 1\n",
    "'''\n",
    "    def __init__(self,X,y):\n",
    "        #The betas of our model\n",
    "        self.betas = self.__fit(X,y,X.shape[1])\n",
    "    def predict(self, X):\n",
    "        #multiply input with our parameters\n",
    "\n",
    "        return np.array([self.__sigmoid(np.dot(x,self.betas)) > 0.5 for x in X])\n",
    "    \n",
    "    def __fit(self, X,y,num_betas):\n",
    "        betas = np.random.randn(num_betas)\n",
    "        #perform gradient descent to find optimum parameter values\n",
    "        betas = self.__gradient_descent(X,y,betas,0.01,1000)\n",
    "        return betas\n",
    "\n",
    "    def __sigmoid(self, x): return (1+np.exp(x)**(-1))**-1\n",
    "\n",
    "    \n",
    "    def __gradient_descent(self,X,y,betas,lr,num_iter):\n",
    "        num_samples = len(X)\n",
    "        for i in range(num_iter):\n",
    "            curr_loss = ((np.dot(X,betas)-y)**2).mean()\n",
    "\n",
    "            #find gradient\n",
    "            gradient = np.zeros_like(betas)\n",
    "            for grad_i in range(len(gradient)):\n",
    "                new_betas = np.zeros_like(gradient)\n",
    "                new_betas[grad_i] += 1\n",
    "                new_betas += betas\n",
    "                new_loss = ((np.dot(X,new_betas)-y)**2).mean()\n",
    "                gradient[grad_i] = new_loss-curr_loss\n",
    "\n",
    "            gradient /= np.linalg.norm(gradient)\n",
    "            betas -= lr * gradient\n",
    "\n",
    "        return betas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:27.861449Z",
     "start_time": "2019-05-24T17:47:27.845987Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:28.022586Z",
     "start_time": "2019-05-24T17:47:28.018797Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:29.334030Z",
     "start_time": "2019-05-24T17:47:28.418349Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressor(data_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:29.340503Z",
     "start_time": "2019-05-24T17:47:29.335869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29267858, -1.22911854,  3.43456091,  4.44180118, -0.74077292,\n",
       "       -0.33820725, -1.45698128, -0.24055598, -1.17273456, -1.10038402,\n",
       "       -0.80629048,  0.93029042, -0.74606624,  3.12430396, -0.99390844,\n",
       "       -0.64349329,  0.57345029,  0.08863091, -0.35640219,  0.04018551,\n",
       "        1.39566022, -0.02059801,  5.59277617, -4.64618428, -1.37885405,\n",
       "        1.38595126,  0.49865575,  1.43484087, -0.855856  ,  0.13223605])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:30.048954Z",
     "start_time": "2019-05-24T17:47:30.043832Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/alan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T17:47:30.579673Z",
     "start_time": "2019-05-24T17:47:30.574955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T19:34:50.334057Z",
     "start_time": "2019-05-24T19:34:50.328952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "#print recall as this is critical for medical tests\n",
    "\n",
    "TP = np.array([prediction and target for prediction,target in zip(predictions,target_test)])\n",
    "FN = np.array([ target and not prediction  for prediction,target in zip(predictions,target_test)])\n",
    "print(TP.sum()/len(predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
